{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5uuLz-FS3_B"
      },
      "source": [
        "# Classes and Functions\n",
        "\n",
        "Execute all cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqmXZoReNPIQ"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "class Grid_Environment:\n",
        "    def __init__ (self, X, Y):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        self.state = (1,1)\n",
        "        self.goal = (X,Y)\n",
        "\n",
        "        states = []\n",
        "        for x in range(X):\n",
        "            for y in range(Y):\n",
        "                states = states + [(x+1,y+1)]\n",
        "        self.states = (*states, )\n",
        "\n",
        "        self.actions = ('w', 's', 'd', 'a' )\n",
        "\n",
        "    moveAction = {\n",
        "        'w': (0,1),\n",
        "        's': (0,-1),\n",
        "        'd': (1,0),\n",
        "        'a': (-1,0)\n",
        "    }\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = (1,1)\n",
        "\n",
        "    def move(self,state,shift):\n",
        "        x = min(max(state[0] + shift[0],1),self.X)\n",
        "        y = min(max(state[1] + shift[1],1),self.Y)\n",
        "        return (x,y)\n",
        "\n",
        "\n",
        "    def reward(self,state, action):\n",
        "        if state == self.goal:\n",
        "            return 0\n",
        "        else:\n",
        "            return -1\n",
        "\n",
        "    def nextState(self,state, action):\n",
        "        nextStates = {}\n",
        "\n",
        "        next = self.move(state,self.moveAction[action])\n",
        "        nextStates[next] = 1.0\n",
        "\n",
        "        return nextStates\n",
        "\n",
        "    def simulateStep(self,state,action):\n",
        "        r = self.reward(state, action)\n",
        "        nextStates = self.nextState(state,action)\n",
        "        return random.choices( list( nextStates.keys() ), weights = list( nextStates.values() ), k=1 )[0], r\n",
        "\n",
        "\n",
        "    def step(self,action):\n",
        "        self.state, r  = self.simulateStep(self.state,action)\n",
        "        return self.state, r\n",
        "\n",
        "    def render(self):\n",
        "        print('')\n",
        "        for j in range(self.Y,0,-1):\n",
        "            for i in range(1,self.X+1):\n",
        "                if self.state == (i,j):\n",
        "                    print('A',end='')\n",
        "                elif self.goal == (i,j):\n",
        "                    print('G',end='')\n",
        "                else:\n",
        "                    print('*',end='')\n",
        "            print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXRns1weZz-2"
      },
      "outputs": [],
      "source": [
        "class GridWind_Environment(Grid_Environment):\n",
        "    windUp = (0,1)\n",
        "    windDown = (0,-1)\n",
        "    windLeft = (-1,0)\n",
        "\n",
        "    def nextState(self,state, action):\n",
        "        nextStates = {}\n",
        "\n",
        "        if self.state[0]/self.X >= 0.5 and self.state[0] < self.X and self.state[1]/self.Y > 0.5:\n",
        "          next = self.move(state,self.moveAction[action])\n",
        "          nextStates[next] = 0.5\n",
        "\n",
        "          next = self.move(state,self.moveAction['w'])\n",
        "          if next in nextStates:\n",
        "              nextStates[next] = nextStates[next] + 0.25\n",
        "          else:\n",
        "              nextStates[next] = 0.25\n",
        "\n",
        "          next = self.move(state,self.moveAction['a'])\n",
        "          if next in nextStates:\n",
        "              nextStates[next] = nextStates[next] + 0.25\n",
        "          else:\n",
        "              nextStates[next] =  0.25\n",
        "\n",
        "        elif self.state[0]/self.X <= 0.5 and self.state[0] > 1 and self.state[1]/self.Y <= 0.5:\n",
        "          next = self.move(state,self.moveAction[action])\n",
        "          nextStates[next] = 0.5\n",
        "\n",
        "          next = self.move(state,self.moveAction['s'])\n",
        "          if next in nextStates:\n",
        "              nextStates[next] = nextStates[next] + 0.25\n",
        "          else:\n",
        "              nextStates[next] =  0.25\n",
        "\n",
        "          next = self.move(state,self.moveAction['a'])\n",
        "          if next in nextStates:\n",
        "              nextStates[next] = nextStates[next] + 0.25\n",
        "          else:\n",
        "              nextStates[next] =  0.25\n",
        "        else:\n",
        "          next = self.move(state,self.moveAction[action])\n",
        "          nextStates[next] = 1.0\n",
        "\n",
        "\n",
        "        return nextStates\n",
        "\n",
        "\n",
        "    def render(self):\n",
        "        print('')\n",
        "        for j in range(self.Y,0,-1):\n",
        "            for i in range(1,self.X+1):\n",
        "                if self.state == (i,j):\n",
        "                    print('A',end='')\n",
        "                elif self.goal == (i,j):\n",
        "                    print('G',end='')\n",
        "                elif i/self.X >= 0.5 and i < self.X and j/self.Y > 0.5:\n",
        "                    print('$',end='')\n",
        "                elif i/self.X <= 0.5 and i > 1 and j/self.Y <= 0.5:\n",
        "                    print('#',end='')\n",
        "                else:\n",
        "                    print('*',end='')\n",
        "            print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ddp9z5FVEWO"
      },
      "outputs": [],
      "source": [
        "class GridInvGoal_Environment(Grid_Environment):\n",
        "\n",
        "    def __init__ (self, X, Y):\n",
        "      Grid_Environment.__init__(self,X,Y)\n",
        "      self.goal = (round(2*X/3),round(Y/3))\n",
        "\n",
        "    def render(self):\n",
        "        print('')\n",
        "        for j in range(self.Y,0,-1):\n",
        "            for i in range(1,self.X+1):\n",
        "                if self.state == (i,j):\n",
        "                    print('A',end='')\n",
        "                # elif self.goal == (i,j):\n",
        "                #     print('G',end='')\n",
        "                else:\n",
        "                    print('*',end='')\n",
        "            print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFQ3m3QeX-Lg"
      },
      "outputs": [],
      "source": [
        "class GridQuad_Environment(Grid_Environment):\n",
        "    Q1 = { 'a' : 'd', 's' : 'w' , 'd' : 'a', 'w':'s' }\n",
        "    Q2 = { 'a' : 'w', 's' : 'a' , 'd' : 's', 'w':'d' }\n",
        "    Q3 = { 'a' : 'w', 's' : 'd' , 'd' : 'a', 'w':'s' }\n",
        "    Q4 = { 'a' : 's', 's' : 'd' , 'd' : 'w', 'w':'a' }\n",
        "\n",
        "    def nextState(self,state, action):\n",
        "        nextStates = {}\n",
        "\n",
        "        if self.state[0]/self.X <= 0.5 and self.state[1]/self.Y <= 0.5:\n",
        "          next = self.move(state,self.moveAction[self.Q2[action]])\n",
        "          nextStates[next] = 1.0\n",
        "        elif self.state[0]/self.X > 0.5 and self.state[1]/self.Y <= 0.5:\n",
        "          next = self.move(state,self.moveAction[self.Q3[action]])\n",
        "          nextStates[next] = 1.0\n",
        "        elif self.state[0]/self.X <= 0.5 and self.state[1]/self.Y > 0.5:\n",
        "          next = self.move(state,self.moveAction[self.Q4[action]])\n",
        "          nextStates[next] = 1.0\n",
        "        elif self.state[0]/self.X > 0.5 and self.state[1]/self.Y > 0.5:\n",
        "          next = self.move(state,self.moveAction[self.Q1[action]])\n",
        "          nextStates[next] = 1.0\n",
        "\n",
        "        return nextStates\n",
        "\n",
        "\n",
        "    def render(self):\n",
        "        print('')\n",
        "        for j in range(self.Y,0,-1):\n",
        "            for i in range(1,self.X+1):\n",
        "                if self.state == (i,j):\n",
        "                    print('A',end='')\n",
        "                elif self.goal == (i,j):\n",
        "                    print('G',end='')\n",
        "                elif i/self.X <= 0.5 and j/self.Y <= 0.5:\n",
        "                    print('$',end='')\n",
        "                elif i/self.X > 0.5 and j/self.Y <= 0.5:\n",
        "                    print('#',end='')\n",
        "                elif i/self.X <= 0.5 and j/self.Y > 0.5:\n",
        "                    print('@',end='')\n",
        "                else:\n",
        "                    print('*',end='')\n",
        "            print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpfEUwaNhFZH"
      },
      "outputs": [],
      "source": [
        "class GridQuadInv_Environment(Grid_Environment):\n",
        "    Q1 = { 'a' : 'd', 's' : 'w' , 'd' : 'a', 'w':'s' }\n",
        "    Q2 = { 'a' : 'w', 's' : 'a' , 'd' : 's', 'w':'d' }\n",
        "    Q3 = { 'a' : 'w', 's' : 'd' , 'd' : 'a', 'w':'s' }\n",
        "    Q4 = { 'a' : 's', 's' : 'd' , 'd' : 'w', 'w':'a' }\n",
        "\n",
        "    def nextState(self,state, action):\n",
        "        nextStates = {}\n",
        "\n",
        "        if self.state[0]/self.X <= 0.3 and self.state[1]/self.Y <= 0.3:\n",
        "          next = self.move(state,self.moveAction[self.Q3[action]])\n",
        "          nextStates[next] = 1.0\n",
        "        elif self.state[0]/self.X > 0.3 and self.state[1]/self.Y <= 0.3:\n",
        "          next = self.move(state,self.moveAction[self.Q4[action]])\n",
        "          nextStates[next] = 1.0\n",
        "        elif self.state[0]/self.X <= 0.3 and self.state[1]/self.Y > 0.3:\n",
        "          next = self.move(state,self.moveAction[self.Q1[action]])\n",
        "          nextStates[next] = 1.0\n",
        "        elif self.state[0]/self.X > 0.3 and self.state[1]/self.Y > 0.3:\n",
        "          next = self.move(state,self.moveAction[self.Q2[action]])\n",
        "          nextStates[next] = 1.0\n",
        "\n",
        "        return nextStates\n",
        "\n",
        "\n",
        "    def render(self):\n",
        "        print('')\n",
        "        for j in range(self.Y,0,-1):\n",
        "            for i in range(1,self.X+1):\n",
        "                if self.state == (i,j):\n",
        "                    print('A',end='')\n",
        "                elif self.goal == (i,j):\n",
        "                    print('G',end='')\n",
        "                # elif i/self.X <= 0.3 and j/self.Y <= 0.3:\n",
        "                #     print('$',end='')\n",
        "                # elif i/self.X > 0.3 and j/self.Y <= 0.3:\n",
        "                #     print('#',end='')\n",
        "                # elif i/self.X <= 0.3 and j/self.Y > 0.3:\n",
        "                #     print('@',end='')\n",
        "                else:\n",
        "                    print('*',end='')\n",
        "            print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAfI5L1PrZkT"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def Simulate(env,maxSteps):\n",
        "  env.reset()\n",
        "  tempo = .25\n",
        "  clear_output(wait=True)\n",
        "  env.render()\n",
        "\n",
        "  steps = 0\n",
        "\n",
        "  while steps < maxSteps:\n",
        "\n",
        "      breakSignal = False\n",
        "      command = input(\"Write 'w', 'a', 's', 'd' to move: \")\n",
        "      for a in command:\n",
        "        s = env.state\n",
        "        if s == env.goal:\n",
        "            breakSignal = True\n",
        "            break\n",
        "        if a in ['w', 'a', 's', 'd']:\n",
        "            env.step(a)\n",
        "            steps += 1\n",
        "\n",
        "        clear_output(wait=True)\n",
        "        env.render()\n",
        "        time.sleep(tempo)\n",
        "      if env.state == env.goal or breakSignal:\n",
        "        break\n",
        "\n",
        "  if env.state == env.goal:\n",
        "    print(f\"Congratulations. You spent {steps} steps to reach the Goal.\")\n",
        "    input(\"Press enter to go to the next task.\")\n",
        "  else:\n",
        "    print(f\"You fail to reach the goal.\")\n",
        "    input(\"Press enter to go to the next task.\")\n",
        "\n",
        "  return steps\n",
        "\n",
        "def EvaluatePolicyMC(env,policy,maxSteps,nSamples):\n",
        "\n",
        "  memSteps = []\n",
        "  memGoals = []\n",
        "\n",
        "  for i in range(nSamples):\n",
        "    env.reset()\n",
        "    steps = 0\n",
        "\n",
        "    while steps < maxSteps:\n",
        "      s = env.state\n",
        "      a = policy[s]\n",
        "      if s == env.goal:\n",
        "          break\n",
        "      if a in ['w', 'a', 's', 'd']:\n",
        "          env.step(a)\n",
        "          steps += 1\n",
        "\n",
        "    if env.state == env.goal:\n",
        "      memGoals = memGoals + [1]\n",
        "      memSteps = memSteps + [steps]\n",
        "    else:\n",
        "      memGoals = memGoals + [0]\n",
        "\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    print(f'Simulating {(i+1)/nSamples}')\n",
        "\n",
        "  print(f'The goal was rechead {100*np.mean(memGoals)}% of the simulations.')\n",
        "  if len(memSteps) > 0:\n",
        "    print(f'The average steps in simulations that rechead the goal was {np.mean(memSteps)}.')\n",
        "\n",
        "  return memSteps, memGoals\n",
        "\n",
        "def SimulatePolicy(env,policy,maxSteps):\n",
        "  env.reset()\n",
        "  tempo = .25\n",
        "  clear_output(wait=True)\n",
        "  env.render()\n",
        "\n",
        "  steps = 0\n",
        "\n",
        "  while steps < maxSteps:\n",
        "    s = env.state\n",
        "    a = policy[s]\n",
        "    if s == env.goal:\n",
        "        break\n",
        "    if a in ['w', 'a', 's', 'd']:\n",
        "        env.step(a)\n",
        "        steps += 1\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    env.render()\n",
        "    time.sleep(tempo)\n",
        "  if env.state == env.goal:\n",
        "    print(f\"Congratulations. You spent {steps} steps to reach the Goal.\")\n",
        "  else:\n",
        "    print(f\"You fail to reach the goal.\")\n",
        "\n",
        "  return steps\n",
        "\n",
        "def SimulatePlan(env,plan):\n",
        "  env.reset()\n",
        "  tempo = .25\n",
        "  clear_output(wait=True)\n",
        "  env.render()\n",
        "\n",
        "  steps = 0\n",
        "\n",
        "  for a in plan:\n",
        "    s = env.state\n",
        "    if s == env.goal:\n",
        "        break\n",
        "    if a in ['w', 'a', 's', 'd']:\n",
        "        env.step(a)\n",
        "        steps += 1\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    env.render()\n",
        "    time.sleep(tempo)\n",
        "  if env.state == env.goal:\n",
        "    print(f\"Congratulations. You spent {steps} steps to reach the Goal.\")\n",
        "  else:\n",
        "    print(f\"You fail to reach the goal.\")\n",
        "\n",
        "  return steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXy7MjujTN7-"
      },
      "source": [
        "#Execution 1: Manual Control\n",
        "\n",
        "Expand the cell, before executing it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "wcEOMGdrOrTz",
        "outputId": "9e4c37f0-23e4-4f79-c788-0f83f315c354"
      },
      "outputs": [],
      "source": [
        "nX = 20\n",
        "nY = 10\n",
        "maxSteps = 300\n",
        "\n",
        "env = Grid_Environment(nX,nY)\n",
        "evalGrid = Simulate(env,maxSteps)\n",
        "\n",
        "env = GridWind_Environment(nX,nY)\n",
        "evalGridWind = Simulate(env,maxSteps)\n",
        "\n",
        "env = GridQuad_Environment(nX,nY)\n",
        "evalGridQuad = Simulate(env,maxSteps)\n",
        "\n",
        "env = GridQuadInv_Environment(nX,nY)\n",
        "evalGridQuadInv = Simulate(env,maxSteps)\n",
        "\n",
        "env = GridInvGoal_Environment(nX,nY)\n",
        "evalGridInvGoal = Simulate(env,maxSteps)\n",
        "\n",
        "clear_output(wait=True)\n",
        "print(f\"Your performance was: {evalGrid}, {evalGridWind}, {evalGridQuad}, {evalGridQuadInv}, {evalGridInvGoal}\")\n",
        "print(f\"Total: {evalGrid+evalGridWind+evalGridQuad+evalGridQuadInv+evalGridInvGoal}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oocpUjqjZ_KF"
      },
      "source": [
        "# Execution 2: Deterministic Plan\n",
        "\n",
        "Expand the cells, before executing them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A976WfKZgG2Q"
      },
      "source": [
        "Define by trial and error a plan by setting the variable **plan**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tV7_BJgZZ0Rr",
        "outputId": "bbef1869-bc65-4fd0-84a8-4f9c3f862b00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "*******************G\n",
            "********************\n",
            "********************\n",
            "********************\n",
            "********************\n",
            "********************\n",
            "********************\n",
            "********************\n",
            "********************\n",
            "*A******************\n",
            "You fail to reach the goal.\n"
          ]
        }
      ],
      "source": [
        "nX = 20\n",
        "nY = 10\n",
        "\n",
        "plan = 'awsd'\n",
        "\n",
        "env = Grid_Environment(nX,nY)\n",
        "eval = SimulatePlan(env, plan)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R11UtyAfgUDp"
      },
      "source": [
        "Define by trial and error a plan by setting the variable **plan**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01yC5wqWb4jf"
      },
      "outputs": [],
      "source": [
        "nX = 20\n",
        "nY = 10\n",
        "\n",
        "plan = 'awsd'\n",
        "\n",
        "env = GridQuad_Environment(nX,nY)\n",
        "eval = SimulatePlan(env, plan)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HaVFsftgVM0"
      },
      "source": [
        "Define by trial and error a plan by setting the variable **plan**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLV0UE2leUCH"
      },
      "outputs": [],
      "source": [
        "nX = 20\n",
        "nY = 10\n",
        "\n",
        "plan = 'awsd'\n",
        "\n",
        "env = GridQuadInv_Environment(nX,nY)\n",
        "eval = SimulatePlan(env, plan)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuxfFuY-efPG"
      },
      "source": [
        "# Execution 3: Policies\n",
        "Expand the cells, before executing them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKzdrd8Bgjp-"
      },
      "source": [
        "Define by trial and error a policy by setting the variable **policy**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUbKeUu2ej9y",
        "outputId": "91c1d871-558b-485a-8e7c-3f7f409f717f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "****$$$$$A\n",
            "****$$$$$*\n",
            "****$$$$$*\n",
            "*####*****\n",
            "*####*****\n",
            "Congratulations. You spent 15 steps to reach the Goal.\n"
          ]
        }
      ],
      "source": [
        "nX = 10\n",
        "nY = 5\n",
        "maxSteps = 100\n",
        "\n",
        "policy = {(1,5): 'a', (2,5): 'a', (3,5): 'a', (4,5): 'a', (5,5): 'a', (6,5): 'a', (7,5): 'a', (8,5): 'a', (9,5): 'a', (10,5): 'w',\n",
        "          (1,4): 'a', (2,4): 'a', (3,4): 'a', (4,4): 'a', (5,4): 'a', (6,4): 'a', (7,4): 'a', (8,4): 'a', (9,4): 'a', (10,4): 'w',\n",
        "          (1,3): 'd', (2,3): 'd', (3,3): 'd', (4,3): 'd', (5,3): 'd', (6,3): 's', (7,3): 's', (8,3): 's', (9,3): 's', (10,3): 'w',\n",
        "          (1,2): 'w', (2,2): 'a', (3,2): 'a', (4,2): 'a', (5,2): 'd', (6,2): 'd', (7,2): 'd', (8,2): 'd', (9,2): 'd', (10,2): 'w',\n",
        "          (1,1): 'w', (2,1): 'd', (3,1): 'd', (4,1): 'd', (5,1): 'd', (6,1): 'd', (7,1): 'd', (8,1): 'd', (9,1): 'd', (10,1): 'w'\n",
        "         }\n",
        "\n",
        "\n",
        "\n",
        "env = GridWind_Environment(nX,nY)\n",
        "eval = SimulatePolicy(env, policy, maxSteps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zti388gigzJg"
      },
      "source": [
        "Evaluate the previously defined policy with Monte Carlo simulation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mSKB6BJJmdjr",
        "outputId": "ad41aeb6-d40f-49f6-a329-e06b791c0ace"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Simulating 1.0\n",
            "The goal was rechead 38.6% of the simulations.\n",
            "The average steps in simulations that rechead the goal was 16.181347150259068.\n"
          ]
        }
      ],
      "source": [
        "maxSteps = 100\n",
        "nSamples = 1000\n",
        "s,g = EvaluatePolicyMC(env, policy, maxSteps, nSamples);"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "g5uuLz-FS3_B",
        "JXy7MjujTN7-",
        "oocpUjqjZ_KF",
        "TuxfFuY-efPG"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
